# -*- coding: utf-8 -*-
"""Desafios_(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yVDUsZ4dmEjOfzA1-4643b1vbLvfzBXr

#Capítulo I

# **Librerías necesarias**

Aquí se importan las librerias necesarias para ejecutar el código
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

import sklearn
from sklearn.model_selection import train_test_split
from sklearn import metrics

import tensorflow as tf
import tensorflow_datasets as tfds

from tensorflow import keras
from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers

from keras.optimizers import Adam, SGD, RMSprop
from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report

from sklearn.model_selection import StratifiedKFold
from scipy.stats import wilcoxon

import shap

"""# **Cargar DataSet Colorectal Histology**

Ejecutando este código cargaremos la base de datos con imágenes
"""

batch_size = 64 # numero de imagenes por iteracion
nb_classes = 2  # 8 si tenemos todo el espacio de soluciones
epochs = 25     # numero de veces que pasa el conjunto de datos a través del modelo
img_rows, img_cols = 32, 32     # escalado de las imagenes resultantes

def format_example(image):
    image = tf.cast(image, tf.float32)       # castea la imagen a float32 para tratarla
    image = image / 255.0                     # la normaliza a valores entre 0 y 1 -> tiene 256 pixeles --> 16x16 pixeles
    image = tf.image.resize(image, (img_rows, img_cols))      # reescala la imagen de 16x16 a 32x32 pixeles
    return image                                            # devuelve la imagen reescalada


def load_data(name="colorectal_histology"):                           # se le indica en name con que tipo de dataset vamos a trabajar (MNIST, colorectal, etc)
  train_ds = tfds.load(name, split=tfds.Split.TRAIN, batch_size=-1)   # carga el dataset "name", split="tfds.Split.TRAIN" indica lote grande con batch -1 en un solo bloque
  train_ds['image'] = tf.map_fn(format_example, train_ds['image'], dtype=tf.float32)    # hace map de la funcion format_example a cada conjunto de train_ds en float32, normaliza y redimensiona en paralelo
  numpy_ds = tfds.as_numpy(train_ds)        # convierte a numpy array para trabajar con funciones numpy
  X, y = numpy_ds['image'], numpy_ds['label']     # X = Imagenes, y = etiquetas

  return np.array(X), np.array(y)         # las devuelve

"""# **Muestra del contenido del DataSet**

Aquí podremos visualizar cuál es el contenido de nuestro DataSet
"""

def show_images(X, y, num_images):
    plt.figure(figsize=(10, 10))  # Tamaño de la figura para la visualización
    for i in range(num_images):
        ax = plt.subplot(1, num_images, i + 1)
        plt.imshow(X[i])  # Muestra la imagen i-ésima
        plt.title(f'Label: {y[i]}')  # Muestra la etiqueta correspondiente
        plt.axis("off")  # Oculta los ejes para mayor claridad
    plt.show()

X, y = load_data()

show_images(X, y, num_images=8)

"""# Análisis de los distintos parámetros de la red

Estudiamos los distintos parámetros de la red

################################
#
#        BATCH_SIZE = 32
#
################################

# Contenidos de las variables
# X_train: 80% de las imágenes originales
# X_test: 20% de las imagenes de prueba originales
# y_train: Etiquetas verdaderas de X_train
# y_test: Etiquetas verdaderas de X_test

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)    # utilizamos 20% prueba 80% entrenamiento con aleatoriedad 24

model = create_model()    # creamos el modelo

history = model.fit(X_train, y_train, epochs=epochs, batch_size=32)               # entrenamos el modelo

y_pred = model.predict(X_test)    # realizamos las predicciones con el modelo entrenado

# Cálculo de AUC

auc = roc_auc_score(y_test, y_pred)    # Calculamos el área bajo la curva ROC
print(f"Resultado de la métrica AUC: {auc:.5f}")

# Cálculo de F1

f1 = f1_score(y_test, np.round(y_pred))    # Calculamos la puntuación F1
print(f"Resultado de la métrica F1: {f1:.5f}")

# Cálculo de Precisión y Recall (otras comparativas)
precision = precision_score(y_test, np.round(y_pred))
recall = recall_score(y_test, np.round(y_pred))

print(f"Resultado de la métrica Precision: {precision:.4f}")    # Predice los que son tumores y de esos calcula los que son de verdad
print(f"Resultado de la métrica Recall: {recall:.4f}")                                  # De los que realmente son tumores calcula cuántos ha predicho que son de verdad tumores

################################
#
#        BATCH_SIZE = 64
#
################################

# Contenidos de las variables
# X_train: 80% de las imágenes originales
# X_test: 20% de las imagenes de prueba originales
# y_train: Etiquetas verdaderas de X_train
# y_test: Etiquetas verdaderas de X_test

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)    # utilizamos 20% prueba 80% entrenamiento con aleatoriedad 24

model = create_model()    # creamos el modelo

history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)               # entrenamos el modelo

y_pred = model.predict(X_test)    # realizamos las predicciones con el modelo entrenado

# Cálculo de AUC

auc_64 = roc_auc_score(y_test, y_pred)    # Calculamos el área bajo la curva ROC
print(f"Resultado de la métrica AUC: {auc:.5f}")

# Cálculo de F1

f1_64 = f1_score(y_test, np.round(y_pred))    # Calculamos la puntuación F1
print(f"Resultado de la métrica F1: {f1:.5f}")

# Cálculo de Precisión y Recall (otras comparativas)
precision_64 = precision_score(y_test, np.round(y_pred))
recall_64 = recall_score(y_test, np.round(y_pred))

print(f"Resultado de la métrica Precision: {precision:.4f}")    # Predice los que son tumores y de esos calcula los que son de verdad
print(f"Resultado de la métrica Recall: {recall:.4f}")                                  # De los que realmente son tumores calcula cuántos ha predicho que son de verdad tumores

Gráfica comparativa del batch_size 32 y batch_size 64

metricas = ['AUC', 'F1 Score', 'Precision', 'Recall']

values_32 = [auc, f1, precision, recall]
values_64 = [auc_64, f1_64, precision_64, recall_64]

x = np.arange(len(metricas))
width = 0.35  # Ancho de las barras

plt.figure(figsize=(10, 6))
plt.bar(x - width/2, values_32, width, label='Batch Size = 32', color='blue')
plt.bar(x + width/2, values_64, width, label='Batch Size = 64', color='green')

plt.xlabel('Métricas')
plt.ylabel('Valores')
plt.title('Comparación de Métricas para Distintos Batch Sizes (32 vs 64)')
plt.xticks(x, metricas)
plt.ylim(0, 1)  # Limitar el eje Y de 0 a 1 para métricas entre 0 y 1
plt.legend(loc='lower right', bbox_to_anchor=(1.15, 1))  # Mover la leyenda fuera del gráfico

plt.show()

Estudio de las épocas

################################
#
#        EPOCHS = 25
#
################################

# Contenidos de las variables
# X_train: 80% de las imágenes originales
# X_test: 20% de las imagenes de prueba originales
# y_train: Etiquetas verdaderas de X_train
# y_test: Etiquetas verdaderas de X_test

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)    # utilizamos 20% prueba 80% entrenamiento con aleatoriedad 24

model = create_model()    # creamos el modelo

history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)               # entrenamos el modelo

y_pred = model.predict(X_test)    # realizamos las predicciones con el modelo entrenado

# Cálculo de AUC

auc = roc_auc_score(y_test, y_pred)    # Calculamos el área bajo la curva ROC
print(f"Resultado de la métrica AUC: {auc:.5f}")

# Cálculo de F1

f1 = f1_score(y_test, np.round(y_pred))    # Calculamos la puntuación F1
print(f"Resultado de la métrica F1: {f1:.5f}")

# Cálculo de Precisión y Recall (otras comparativas)
precision = precision_score(y_test, np.round(y_pred))
recall = recall_score(y_test, np.round(y_pred))

print(f"Resultado de la métrica Precision: {precision:.4f}")    # Predice los que son tumores y de esos calcula los que son de verdad
print(f"Resultado de la métrica Recall: {recall:.4f}")                                  # De los que realmente son tumores calcula cuántos ha predicho que son de verdad tumores

################################
#
#        EPOCHS = 50
#
################################

# Contenidos de las variables
# X_train: 80% de las imágenes originales
# X_test: 20% de las imagenes de prueba originales
# y_train: Etiquetas verdaderas de X_train
# y_test: Etiquetas verdaderas de X_test

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)    # utilizamos 20% prueba 80% entrenamiento con aleatoriedad 24

model = create_model()    # creamos el modelo

history = model.fit(X_train, y_train, epochs=50, batch_size=batch_size)               # entrenamos el modelo

y_pred = model.predict(X_test)    # realizamos las predicciones con el modelo entrenado

# Cálculo de AUC

auc_50 = roc_auc_score(y_test, y_pred)    # Calculamos el área bajo la curva ROC
print(f"Resultado de la métrica AUC: {auc:.5f}")

# Cálculo de F1

f1_50 = f1_score(y_test, np.round(y_pred))    # Calculamos la puntuación F1
print(f"Resultado de la métrica F1: {f1:.5f}")

# Cálculo de Precisión y Recall (otras comparativas)
precision_50 = precision_score(y_test, np.round(y_pred))
recall_50 = recall_score(y_test, np.round(y_pred))

print(f"Resultado de la métrica Precision: {precision:.4f}")    # Predice los que son tumores y de esos calcula los que son de verdad
print(f"Resultado de la métrica Recall: {recall:.4f}")                                  # De los que realmente son tumores calcula cuántos ha predicho que son de verdad tumores

Gráfica comparativa de las épocas

metricas = ['AUC', 'F1 Score', 'Precision', 'Recall']

values_25 = [auc, f1, precision, recall]
values_50 = [auc_50, f1_50, precision_50, recall_50]

x = np.arange(len(metricas))
width = 0.35  # Ancho de las barras

plt.figure(figsize=(10, 6))
plt.bar(x - width/2, values_25, width, label='Epochs = 25', color='blue')
plt.bar(x + width/2, values_50, width, label='Epochs = 50', color='green')

plt.xlabel('Métricas')
plt.ylabel('Valores')
plt.title('Comparación de Métricas para Distintas Epochs (25 vs 50)')
plt.xticks(x, metricas)
plt.ylim(0, 1)  # Limitar el eje Y de 0 a 1 para métricas entre 0 y 1
plt.legend(loc='lower right', bbox_to_anchor=(1.15, 1))  # Mover la leyenda fuera del gráfico

plt.show()

Concluimos que usaremos como batch_size = 64 y epochs = 25

Comparación de los distintos optimizers

# Definimos la función para crear el modelo a entrenar con distintos optimizers (clasificación binaria)
def create_model_aux(optimizer):
    model = Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),    # aplicamos filtros a imagenes de 32x32 con activacion relu
        layers.MaxPooling2D(pool_size=(2, 2)),                                                # aplicamos max pooling para reducir dimensionalidad
        layers.Flatten(),                                                                     # aplanamos
        layers.Dense(128, activation='relu'),                                                 # aplicamos una capa oculta de 128 neuronas con activacion relu
        layers.Dense(1, activation='sigmoid')                                                 # utilizamos sigmoid para clasificación binaria
    ])
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])        # binary_crossentropy porque tenemos clasificación binaria
    return model

################################
#
#    COMPARATIVA DE OPTIMIZERS
#
################################

# Contenidos de las variables
# X_train: 80% de las imágenes originales
# X_test: 20% de las imagenes de prueba originales
# y_train: Etiquetas verdaderas de X_train
# y_test: Etiquetas verdaderas de X_test

optimizers = {
    'Adam': Adam(),
    'SGD con Momentum': SGD(momentum=0.9),
    'RMSprop': RMSprop()
}

auc_values = []
f1_values = []
precision_values = []
recall_values = []

for nombre, optimizer in optimizers.items():
    print(f"Entrenando con {nombre} optimizer...")
    model = create_model(optimizer)
    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)  # entrenamos el modelo
    y_pred = model.predict(X_test)    # realizamos las predicciones con el modelo entrenado

    auc = roc_auc_score(y_test, y_pred)
    f1 = f1_score(y_test, np.round(y_pred))
    precision = precision_score(y_test, np.round(y_pred))
    recall = recall_score(y_test, np.round(y_pred))

    auc_values.append(auc)
    f1_values.append(f1)
    precision_values.append(precision)
    recall_values.append(recall)

    print(f"Resultado de la métrica AUC: {auc:.5f}")
    print(f"Resultado de la métrica F1: {f1:.5f}")
    print(f"Resultado de la métrica Precision: {precision:.4f}")
    print(f"Resultado de la métrica Recall: {recall:.4f}")

Gráfica comparativa de los distintos optimizers

# Representación gráfica de las métricas comparativas
metricas = ['AUC', 'F1 Score', 'Precision', 'Recall']
nombres = list(optimizers.keys())

# Valores de las métricas para cada optimizador
data = [auc_values, f1_values, precision_values, recall_values]

x = np.arange(len(nombres))
width = 0.2  # Ancho de las barras

plt.figure(figsize=(12, 8))
for i, metric in enumerate(metricas):
    plt.bar(x + i * width, data[i], width, label=metric)

# Configuraciones del gráfico
plt.xlabel('Optimizers')
plt.ylabel('Valores de las Métricas')
plt.title('Comparación de Optimizers para Diferentes Métricas')
plt.xticks(x + width, nombres)
plt.ylim(0, 1)  # Limitar el eje Y de 0 a 1 para métricas entre 0 y 1
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))
plt.show()

Concluimos que utilizaremos SGD con Momentum como optimizer

## **Básico**

Clasificación binaria sobre si el tejido está identificado como TUMOR (etiquetado como 0) respecto del resto de tejidos (etiquetados del 1 al 7)
"""

#################################################
#
#                  MAIN
#
##################################################

X, y = load_data()        # en y tenemos las etiquetas de las imagenes (lo que son verdaderamente)

if nb_classes == 2:       # convertimos las etiquetas que no son tumor a clase 1 --> NO ES TUMOR, las de clase 0 --> ES TUMOR
  y[y>0] = 1

# Comprobaciones de lo que observamos arriba
print(f"Contenido de la etiqueta 4 (Tumor): {y[3]}")
print(f"Contenido de la etiqueta 1 (No tumor): {y[0]}")

# Ver distribución de clases
unique, counts = np.unique(y, return_counts=True)
print(f"Distribución de clases: {dict(zip(unique, counts))}")

"""Gráfica comparativa de la distribución de clases"""

#################################################
#
#          Gráfica comparativa de clases
#
##################################################

# Extraer etiquetas y cantidades
labels = [f'Clase {int(label)}' for label in unique]

# Crear la gráfica de barras
plt.figure(figsize=(8, 6))
plt.bar(labels, counts, color=['red', 'green'])
plt.xlabel('Clase')
plt.ylabel('Cantidad')
plt.title('Distribución de Clases: TUMOR vs NO TUMOR')
plt.show()

"""
Dado que tendremos un desequilibrio considerable con las clases estudiaremos sólo la métrica AUC y opcionalmente la F1"""

#################################################
#
#                Creación del modelo
#
##################################################

# Definimos la función para crear el modelo a entrenar (clasificación binaria)

def create_model(optimizer='sgd_momentum'):
    if optimizer == 'adam':         # comprobación de los optimizadores usados para wilcoxon, etc
        optimizer_usado = Adam()
    elif optimizer == 'sgd':
        optimizer_usado = SGD()
    elif optimizer == 'sgd_momentum':
        optimizer_usado = SGD(momentum=0.9)
    elif optimizer == 'rmsprop':
        optimizer_usado = RMSprop()
    else:
        raise ValueError("Optimizer no soportado. Por favor, elige entre 'adam', 'sgd', 'sgd_momentum' o 'rmsprop'.")

    model = Sequential([
      layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),    # aplicamos filtros a imagenes de 32x32 con activacion relu
      layers.MaxPooling2D(pool_size=(2, 2)),                                                # aplicamos max pooling para reducir dimensionalidad
      layers.Flatten(),                                                                     # aplanamos
      layers.Dense(128, activation='relu'),                                                 # aplicamos una capa oculta de 128 neuronas con activacion relu
      layers.Dense(1, activation='sigmoid')                                                 # utilizamos sigmoid para clasificación binaria
    ])
    model.compile(optimizer=optimizer_usado, loss='binary_crossentropy', metrics=['accuracy'])        # binary_crossentropy porque tenemos clasificación binaria
    return model

#################################################
#
#  Entrenamiento del modelo y obtención de AUC y F1
#
##################################################

# Contenidos de las variables
# X_train: 80% de las imágenes originales
# X_test: 20% de las imagenes de prueba originales
# y_train: Etiquetas verdaderas de X_train
# y_test: Etiquetas verdaderas de X_test

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)     # utilizamos 20% prueba 80% entrenamiento con aleatoriedad 24
model = create_model()                                                                        # creamos el modelo
history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)                   # entrenamos el modelo
y_pred = model.predict(X_test)                                                                # realizamos las predicciones con el modelo entrenado

auc = roc_auc_score(y_test, y_pred)                                                           # calculamos AUC
print(f"Resultado de la métrica AUC: {auc:.5f}")
f1 = f1_score(y_test, np.round(y_pred))                                                       # calculamos F1
print(f"Resultado de la métrica F1: {f1:.5f}")

y_pred_redondeado = np.round(y_pred)                                                          # redondear las predicciones para que sean 0 o 1
matriz_confusion = confusion_matrix(y_test, y_pred_redondeado)
print(f"Matriz de Confusión:\n{matriz_confusion}\n")                                          # mostramos la matriz de confusion

target_names = ['TUMOR', 'HEALTHY'] if nb_classes ==  2 else ['TUMOR','STROMA','COMPLEX','LYMPHO','DEBRIS','MUCOSA','ADIPOSE','EMPTY']
print(classification_report(y_test, y_pred_redondeado, target_names=target_names))

"""Aplicación de la validación cruzada 10-CV"""

#################################################
#
#    Aplicación de la validación cruzada 10-CV
#
##################################################

skf = StratifiedKFold(n_splits=10) # dividimos el dataset en 10 pliegues manteniendo la proporción entre clases
auc_scores_10cv = []   # guardamos el area bajo la curva en cada pliegue

for train_index, test_index in skf.split(X, y):
    X_train, X_test = X[train_index], X[test_index]   # dividimos datos en entrenamiento y prueba
    y_train, y_test = y[train_index], y[test_index]

    model = None
    model = create_model()                              # creamos un nuevo modelo en cada pliegue
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\
              verbose=0, validation_data=(X_test, y_test))  # entrenamos el modelo actual

    y_pred = model.predict(X_test).ravel()       # realiza predicciones  sobre los datos de prueba y lo aplana a unidimensional
    auc_10cv = roc_auc_score(y_test, y_pred)     # area bajo la curva roc
    auc_scores_10cv.append(auc_10cv)             # guardamos los valores de AUC en cada split para graficar

print(f"Media de AUC (10-CV): {np.mean(auc_scores_10cv):.4f} en los {skf.get_n_splits()} pliegues")  # mostramos la media de 10-CV
print(f"Desviación estándar de AUC (10-CV): {np.std(auc_scores_10cv):.4f} en los {skf.get_n_splits()} pliegues")  # mostramos la desviación estándar de 10-CV

"""Gráfica comparativa de la desviación de AUC en cada pliegue de 10-CV"""

#######################################################
#
#   Gráfica comparativa de la desviación estándar 10CV
#
########################################################

plt.figure(figsize=(10, 6))
plt.bar(range(1, 11), auc_scores_10cv, color='skyblue')
plt.xlabel('Número de Pliegue')
plt.ylabel('AUC')
plt.title('AUC en Cada Pliegue de Validación Cruzada (10-CV)')
plt.ylim(0.9, 1.0)  # Ajuste del rango para visualizar bien los valores
plt.show()

"""Estudio estadístico de Wilcoxon

Vamos a comparar los distintos optimizadores con 10-CV (Adam, SGD with Momentum, SGD, RMSprop)
"""

#####################################################
#
#   Cálculo de AUC para cada optimizador
#
#####################################################

optimizers = ['adam', 'sgd', 'rmsprop', 'sgd_momentum']
auc_results_per_optimizer = {}           # diccionario para guardar optimizador y resultados de auc

for nombre in optimizers:
  skf = StratifiedKFold(n_splits=10)      # numero de splits
  auc_results_per_optimizer[nombre] = []      # inicializamos cada lista de auc por optimizer a vacio
  print(f"Entrenando con {nombre} optimizer...")
  for train_index, test_index in skf.split(X, y):
    X_train, X_test = X[train_index], X[test_index]   # dividimos datos en entrenamiento y prueba
    y_train, y_test = y[train_index], y[test_index]

    model = None
    model = create_model(optimizer=nombre)         # creamos el modelo con el optimizer
    model.fit(X_train, y_train, epochs=epochs,\
              batch_size=batch_size)                  # entrenamos el modelo

    y_pred = model.predict(X_test).ravel()            # calculamos las predicciones y aplanamos a unidimensional
    auc_results_per_optimizer[nombre].append(roc_auc_score(y_test, y_pred))     # añadimos los valores de AUC de cada optimizer en cada split
    print(f"AUC para el optimizador {nombre} en el pliegue actual: {roc_auc_score(y_test, y_pred):.4f}")

"""Generación de gráficas comparativas para calcular el Test de Wilcoxon"""

#####################################################
#
#   Test de Wilcoxon con los distintos optimizadores
#
#####################################################

wilcoxon_results = {}
best = optimizers[0]  # coger el primer optimizador como el mejor

for i in range(1, len(optimizers)):
    opt1 = best
    opt2 = optimizers[i]

    stat, p_value = wilcoxon(auc_results_per_optimizer[opt1], auc_results_per_optimizer[opt2])  # calculo de wilcoxon
    wilcoxon_results[(opt1, opt2)] = p_value
    print(f"Wilcoxon test entre {opt1} y {opt2}: p-value = {p_value:.3f}")

    if p_value < 0.05:
        best = opt2         # si p<0.05 es mejor el segundo

"""Gráfica generada para el análisis"""

############################################
#
#   Generación de gráfica sobre Wilcoxon
#
############################################

comparisons = [f"{opt1} vs {opt2}" for (opt1, opt2) in wilcoxon_results.keys()]  # guardamos cada par de combinaciones de optimizadores
p_values = [p for p in wilcoxon_results.values()]                                # guardamos cada valor de p para cada par

plt.figure(figsize=(10, 6))
plt.bar(comparisons, p_values, color='skyblue')
plt.xlabel('Comparación de Optimizadores')
plt.ylabel('Valor p')
plt.title('Comparación de Optimizadores con Valores p (Wilcoxon)')
plt.axhline(y=0.05, color='r', linestyle='--', label='Nivel de significancia (p = 0.05)')
plt.legend()
plt.ylim(0, 1)
plt.show()

"""Uso de técnicas de aumentado de datos sencillas como ImageDataGenerator de
tf.Keras configurado convenientemente para equilibrar el número de muestras en la clase minoritaria

Pequeño ejemplo ilustrativo de las nuevas imágenes que se generan
"""

##############################################################
#
#   Ilustración del aumentado de datos con ImageDataGenerator
#
##############################################################

generador_datos = ImageDataGenerator(
    rotation_range=15,                  # rotacion de (-15, +15) grados
    width_shift_range=0.15,             # desplazamiento horizontal de hasta 15%
    height_shift_range=0.15,            # desplazamiento vertical de hasta 15%
    horizontal_flip=True,               # voltear imagenes en horizontal
    fill_mode='reflect',                # rellenar pixeles con el reflejo de los cercanos
    shear_range=0.2,                    # distorsion del 20%
    zoom_range=[0.8, 1.2],              # zoom entre 80% y 120%
)

num_clases = np.bincount(y)                                   # obtenemos el numero de imagenes en las clases 0 y 1
imagenes_a_generar = num_clases[1] - num_clases[0]            # obtenemos cuantas tenemos que generar para equilibrar

X_clase_0 = X[y == 0]                                         # seleccionamos imagenes y etiquetas de clase 0
y_clase_0 = y[y == 0]

generador_clase_0 = generador_datos.flow(X_clase_0, y_clase_0, batch_size=1, shuffle=False)

nueva_X_clase_0 = []
nueva_y_clase_0 = []

for _ in range(imagenes_a_generar):
    img, label = next(generador_clase_0)
    nueva_X_clase_0.append(img[0])           # extraer la primera (y unica) imagen del batch
    nueva_y_clase_0.append(label[0])         # extraer la etiqueta correspondiente


nueva_X_clase_0 = np.array(nueva_X_clase_0)   # convertirlo a numpy array
nueva_y_clase_0 = np.array(nueva_y_clase_0)

nuevo_X = np.concatenate([X, nueva_X_clase_0], axis=0)    # concatenar las de inicio con las nuevas imagenes
nuevo_y = np.concatenate([y, nueva_y_clase_0], axis=0)

indices = np.arange(len(nuevo_X))    # barajar los indices
np.random.shuffle(indices)
nuevo_X = nuevo_X[indices]
nuevo_y = nuevo_y[indices]

print("Forma de las imágenes equilibradas:", nuevo_X.shape)
print("Distribución de clases:", np.bincount(nuevo_y))

show_images(nuevo_X, nuevo_y, num_images=10)

"""Función utilizada para generar nuevas imágenes"""

##############################################
#
#   Aumentado de datos con ImageDataGenerator
#
##############################################

def generar_imagenes_clase_0(generador_datos, X, y):

  num_clases = np.bincount(y)                                   # obtenemos el numero de clases (0 o 1)
  imagenes_a_generar = num_clases[1] - num_clases[0]            # obtenemos cuantas tenemos que generar para equilibrar

  X_clase_0 = X[y == 0]                                         # seleccionamos imagenes y etiquetas de clase 0
  y_clase_0 = y[y == 0]

  generador_clase_0 = generador_datos.flow(X_clase_0, y_clase_0, batch_size=1, shuffle=False)

  nueva_X_clase_0 = []
  nueva_y_clase_0 = []

  for _ in range(imagenes_a_generar):
      img, label = next(generador_clase_0)
      nueva_X_clase_0.append(img[0])           # extraer la primera (y unica) imagen del batch
      nueva_y_clase_0.append(label[0])         # extraer la etiqueta correspondiente


  nueva_X_clase_0 = np.array(nueva_X_clase_0)   # convertirlo a numpy array
  nueva_y_clase_0 = np.array(nueva_y_clase_0)

  nuevo_X = np.concatenate([X, nueva_X_clase_0], axis=0)    # concatenar las de inicio con las nuevas imagenes
  nuevo_y = np.concatenate([y, nueva_y_clase_0], axis=0)

  indices = np.arange(len(nuevo_X))    # barajar los indices
  np.random.shuffle(indices)
  nuevo_X = nuevo_X[indices]
  nuevo_y = nuevo_y[indices]

  return nuevo_X, nuevo_y

'''
generador_datos = ImageDataGenerator(
    rotation_range=15,                  # rotacion de (-15, +15) grados
    width_shift_range=0.15,             # desplazamiento horizontal de hasta 15%
    height_shift_range=0.15,            # desplazamiento vertical de hasta 15%
    horizontal_flip=True,               # voltear imagenes en horizontal
    fill_mode='reflect',                # rellenar pixeles con el reflejo de los cercanos
    shear_range=0.2,                    # distorsion del 20%
    zoom_range=[0.8, 1.2],              # zoom entre 80% y 120%
)

X_balanced, y_balanced = generar_imagenes_clase_0(generador_datos, X, y)

# Separar los conjuntos de entrenamiento y validación
X_train, X_val, y_train, y_val = train_test_split(X_balanced, y_balanced, test_size=0.1, random_state=42)

# Entrenar el modelo con el conjunto equilibrado
history = model.fit(
    generador_datos.flow(X_train, y_train, batch_size=32),
    steps_per_epoch=len(X_train) // 32,
    epochs=epochs,
    validation_data=(X_val, y_val)
)

# Predicciones para el conjunto de validación
y_pred_prob = model.predict(X_val).ravel()  # Obtener las probabilidades de la clase positiva
y_true = y_val  # Etiquetas verdaderas

# Calcular AUC
auc_score = roc_auc_score(y_true, y_pred_prob)
print(f"AUC en el conjunto de validación: {auc_score:.4f}")
'''

"""Aplicación de las nuevas imágenes en 10-CV"""

##############################################
#
#   Aplicación de 10-CV con ImageDataGenerator
#
##############################################

generador_datos = ImageDataGenerator(
    rotation_range=50,                  # rotacion de (-15, +15) grados
    width_shift_range=0.50,             # desplazamiento horizontal de hasta 15%
    height_shift_range=0.50,            # desplazamiento vertical de hasta 15%
    horizontal_flip=True,               # voltear imagenes en horizontal
    fill_mode='reflect',                # rellenar pixeles con el reflejo de los cercanos
    shear_range=0.25,                    # distorsion del 20%
    zoom_range=[0.5, 1.5],              # zoom entre 80% y 120%
)

sfk = StratifiedKFold(n_splits=10)
auc_scores = []

for train_idx, test_idx in sfk.split(X, y):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    X_train, y_train = generar_imagenes_clase_0(generador_datos, X_train, y_train)

    X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=24)

    model = create_model()
    history = model.fit(X_train_final, y_train_final,
                        steps_per_epoch=len(X_train_final) // 64,
                        epochs=epochs, batch_size=batch_size,
                        validation_data=(X_val, y_val))

    y_pred_prob = model.predict(X_test).ravel()
    auc_score = roc_auc_score(y_test, y_pred_prob)
    auc_scores.append(auc_score)

    print(f"AUC para este pliegue: {auc_score:.4f}")

print(f"AUC promedio en validación cruzada 10CV: {np.mean(auc_scores):.4f}")
print(f"Desviación estándar de AUC: {np.std(auc_scores):.4f}")

"""Generación de gráfica comparativa de distintos filtros de ImageDataGenerator"""

generador_1 = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    fill_mode='reflect',
    shear_range=0.1,
    zoom_range=[0.9, 1.1]
)

generador_2 = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    shear_range=0.15,
    zoom_range=[0.8, 1.2]
)

generador_3 = ImageDataGenerator(
    rotation_range=5,
    width_shift_range=0.05,
    height_shift_range=0.05,
    horizontal_flip=False,
    fill_mode='constant',
    shear_range=0,
    zoom_range=[0.95, 1.05]
)

generadores = [generador_1, generador_2, generador_3]
generador_nombres = ['Generador 1', 'Generador 2', 'Generador 3']

sfk = StratifiedKFold(n_splits=10)
resultados_auc = []

for i, generador in enumerate(generadores):
    auc_scores = []
    print(f"\nEvaluando {generador_nombres[i]}:")

    for train_idx, test_idx in sfk.split(X, y):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        # Generar datos balanceados para este pliegue
        X_train_balanced, y_train_balanced = generar_imagenes_clase_0(generador, X_train, y_train)

        # Entrenamiento y validación
        model = create_model()
        model.fit(
            X_train_balanced, y_train_balanced,
            epochs=epochs,
            validation_data=(X_test, y_test),
            verbose=0  # Suprime detalles del entrenamiento
        )

        # Calcular AUC para el conjunto de prueba
        y_pred_prob = model.predict(X_test).ravel()
        auc_score = roc_auc_score(y_test, y_pred_prob)
        auc_scores.append(auc_score)
        print(f"AUC en este pliegue: {auc_score:.4f}")

    # Guardar los resultados de AUC promedio para este generador
    resultados_auc.append(auc_scores)
    print(f"AUC promedio para {generador_nombres[i]}: {np.mean(auc_scores):.4f}")

plt.figure(figsize=(10, 6))
for i, auc_scores in enumerate(resultados_auc):
    plt.plot(range(1, 11), auc_scores, marker='o', label=generador_nombres[i])

plt.title('Comparación de AUC entre diferentes ImageDataGenerator')
plt.xlabel('Pliegue (Fold)')
plt.ylabel('AUC')
plt.ylim(0.5, 1.0)
plt.legend()
plt.grid(True)
plt.show()

"""## **Intermedio**

Clasificación con todas las categorías (0..7)
"""

###################################
#
#    Multiclase
#
###################################

nb_classes = 8
batch_size = 32
epochs = 50

X, y = load_data()

"""Creamos un modelo multiclase"""

####################################
#
#   Creación del modelo multiclase
#
####################################

def create_model_multiclass(optimizer='adam'):
    if optimizer == 'adam':
        optimizer_usado = Adam()
    elif optimizer == 'sgd':
        optimizer_usado = SGD()
    elif optimizer == 'sgd_momentum':
        optimizer_usado = SGD(momentum=0.9)
    elif optimizer == 'rmsprop':
        optimizer_usado = RMSprop()
    else:
        raise ValueError("Optimizer no soportado. Por favor, elige entre 'adam', 'sgd', 'sgd_momentum' o 'rmsprop'.")

    model = Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.5),                              # regularización
        layers.Dense(nb_classes, activation='softmax')    # 8 neuronas de salida
    ])
    model.compile(optimizer=optimizer_usado, loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # cambia la perdida a sparse_categorical_crossentropy al ser multiclase

    return model

"""Entrenamos el modelo para las 8 categorías"""

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=24)

model = create_model_multiclass()
history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))

y_pred_multiclass = model.predict(X_val)

y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=nb_classes)    # y_val pasa a una matriz binaria

auc_score = roc_auc_score(y_val_one_hot, y_pred_multiclass, average='macro', multi_class='ovr')  # calculo de AUC

print(f'AUC (macro promedio): {auc_score:.4f}')

"""Dado que ahora el número de ejemplos por categoría estará equilibrado
estudiaremos las métricas AUC y F1

Gráfica con las distintas clases y cantidad de imágenes en cada una
"""

# Obtener las clases únicas y la cantidad de ejemplos por clase
unique_classes, counts_per_class = np.unique(y, return_counts=True)

# Graficar la cantidad de ejemplos por clase
plt.figure(figsize=(8, 5))
plt.bar(unique_classes, counts_per_class, color='skyblue')
plt.xlabel('Categoría')
plt.ylabel('Cantidad de Ejemplos')
plt.title('Distribución de Ejemplos por Categoría')
plt.xticks(unique_classes)
plt.show()

"""Entrenamiento del modelo para calcular AUC y F1"""

optimizadores = ['adam', 'sgd', 'sgd_momentum', 'rmsprop']
resultados = {}

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=24)

for optimizador in optimizadores:
    print(f"Entrenando con optimizador: {optimizador}")
    model = create_model_multiclass(optimizador)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=0)

    y_pred_multiclass = model.predict(X_val)
    y_pred = np.argmax(y_pred_multiclass, axis=1)

    y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=8)

    auc_score = roc_auc_score(y_val_one_hot, y_pred_multiclass, average='macro', multi_class='ovr')
    f1 = f1_score(y_val, y_pred, average='macro')

    resultados[optimizador] = {
        "AUC": auc_score,
        "F1": f1
    }


for optimizador, metricas in resultados.items():
    print(f"Optimizador: {optimizador}")
    print(f"  AUC: {metricas['AUC']:.4f}")
    print(f"  F1 Score: {metricas['F1']:.4f}\n")

"""Gráfica comparativa de los distintos optimizadores en multiclase"""

labels = list(resultados.keys())
auc_values = [metricas['AUC'] for metricas in resultados.values()]
f1_values = [metricas['F1'] for metricas in resultados.values()]

x = np.arange(len(labels))  # posiciones de los grupos
width = 0.35  # ancho de las barras

fig, ax = plt.subplots(figsize=(10, 6))
bars1 = ax.bar(x - width/2, auc_values, width, label='AUC', color='skyblue')
bars2 = ax.bar(x + width/2, f1_values, width, label='F1 Score', color='lightgreen')

# titulos y labels de los ejes
ax.set_xlabel('Optimizadores')
ax.set_ylabel('Puntuación')
ax.set_title('Comparación de AUC y F1 Score para Diferentes Optimizadores')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

"""Ajustes combinados (adición de capas, parámetros de convolución y escalado de imágenes)

Reescalado de las imágenes del dataset
"""

import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
from sklearn.model_selection import train_test_split

########################################
#
#   Cargar datos (nuevo tamaño imagen)
#
########################################

def load_data_resized(name="colorectal_histology"):           # misma manera de cargar los datos pero reescalando las imagenes
    train_ds = tfds.load(name, split=tfds.Split.TRAIN, batch_size=-1)
    train_ds['image'] = tf.map_fn(lambda x: tf.cast(x, tf.float32) / 255.0, train_ds['image'], dtype=tf.float32)
    train_ds['image'] = tf.image.resize(train_ds['image'], (16, 16))    # 16x16 pixeles cada imagen
    numpy_ds = tfds.as_numpy(train_ds)
    X, y = numpy_ds['image'], numpy_ds['label']
    return np.array(X), np.array(y)

X, y = load_data_resized()

print(f"Shape de X: {X.shape}")

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=24)

show_images(X_train, y_train, num_images=5)

"""Nuevo modelo para probar varias configuraciones"""

################################################
#
#   Modelo para probar distintas configuraciones
#
#################################################

def create_model_n_layers_n_filters(n_layers, n_filters, size=16):
    model = tf.keras.Sequential()

    for i in range(n_layers):     #  añadir n_layers capas al modelo
        if i == 0:
            model.add(tf.keras.layers.Conv2D(n_filters, (3, 3), activation='relu', input_shape=(size, size, 3)))  # primera capa convolucional indica el tamaño de las imagenes y los canales
        else:
            model.add(tf.keras.layers.Conv2D(n_filters, (3, 3), activation='relu'))

        if i > 0 and i % 3 == 0:
            model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))   # reducir dimensiones cada 3 capas

    model.add(tf.keras.layers.GlobalAveragePooling2D())     # evitamos flatten y usamos globalaveragepooling2d para evitar dimensiones muy reducidas

    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(128, activation='relu'))
    model.add(tf.keras.layers.Dense(64, activation='relu'))
    model.add(tf.keras.layers.Dropout(0.5))
    model.add(tf.keras.layers.Dense(8, activation='softmax'))   # por ser multiclase se usa softmax

    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    return model

"""Poner a prueba los distintos parámetros"""

################################################
#
#   Prueba del modelo con distintos parámetros
#
#################################################


layers_list = [1, 3, 5]
filters_list = [16, 32, 64, 128]
resultados = {}

for layer in layers_list:
    for filter in filters_list:
        print(f"Entrenando con {layer} capas y {filter} filtros por capa")

        model = None
        model = create_model_n_layers_n_filters(layer, filter, size=16)
        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=0)

        y_pred_multiclass = model.predict(X_val)
        y_pred = np.argmax(y_pred_multiclass, axis=1)

        y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=8)
        auc_score = roc_auc_score(y_val_one_hot, y_pred_multiclass, average='macro', multi_class='ovr')
        f1 = f1_score(y_val, y_pred, average='macro')

        key = str(layer) + "," + str(filter)
        resultados[key] = {
            "AUC": auc_score,
            "F1": f1
        }
        print(f"Valor de AUC: {auc_score} y F1: {f1} para capa {layer} y filtros {filter}")

"""Gráficas comparativas con distintos parámetros"""

################################################
#
#   Gráficas comparativas
#
#################################################


labels = list(resultados.keys())
auc_values = [metrics['AUC'] for metrics in resultados.values()]
f1_values = [metrics['F1'] for metrics in resultados.values()]

x = np.arange(len(labels))  # posiciones de los grupos
width = 0.35  # ancho de las barras

fig, ax = plt.subplots(figsize=(12, 8))
bars1 = ax.bar(x - width/2, auc_values, width, label='AUC', color='skyblue')
bars2 = ax.bar(x + width/2, f1_values, width, label='F1 Score', color='lightgreen')

ax.set_xlabel('Configuraciones de Capas y Filtros')
ax.set_ylabel('Puntuación de cada métrica')
ax.set_title('Comparación de AUC y F1 Score para Diferentes Configuraciones de Capas y Filtros')
ax.set_xticks(x)
ax.set_xticklabels(labels, rotation=45, ha='right')
ax.legend()

"""Ajuste del algoritmo de optimización (mejores resultados con menos épocas con algoritmos externos NO implementados en tf.keras)

Instalación de tensorflow-addons junto a tensorflow compatible
"""

!pip install tensorflow==2.12.0
!pip uninstall tensorflow-addons -y
!pip install tensorflow-addons --upgrade

"""Cargar la librería"""

import tensorflow_addons as tfa
from tensorflow_addons.optimizers import Lookahead
import tensorflow as tf
import tensorflow_datasets as tfds
from sklearn.metrics import roc_auc_score, f1_score
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, f1_score

"""Cargar los datos"""

X, y = load_data_resized()

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=24)

"""Utilizar el optimizador Ranger de tensorflow_addons"""

######################################
#
#   Pruebas con optimizador Ranger
#
######################################

radam_optimizer = tfa.optimizers.RectifiedAdam(learning_rate=0.001)
ranger_optimizer = Lookahead(radam_optimizer, sync_period=5)  # lookahead se aplica sobre RAdam

model = create_model_n_layers_n_filters(3, 32, size=16)
model.compile(optimizer=ranger_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=15, batch_size=batch_size, validation_data=(X_val, y_val), verbose=0)

y_pred_multiclass = model.predict(X_val)
y_pred = np.argmax(y_pred_multiclass, axis=1)
y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=8)

auc_score_ranger = roc_auc_score(y_val_one_hot, y_pred_multiclass, average='macro', multi_class='ovr')
f1_ranger = f1_score(y_val, y_pred, average='macro')

print(f"AUC (macro promedio usando Ranger): {auc_score_ranger:.4f}")
print(f"F1 Score (macro promedio usando Ranger): {f1_ranger:.4f}")

"""Uso del optimizador AdaBelief"""

from tensorflow_addons.optimizers import AdaBelief
from tensorflow_addons.optimizers import LAMB

######################################
#
#   Pruebas con optimizador AdaBelief
#
######################################

adabelief_optimizer = AdaBelief(learning_rate=0.001)

model = create_model_n_layers_n_filters(3, 32, size=16)
model.compile(optimizer=adabelief_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), batch_size=batch_size, verbose=0)

y_pred_multiclass = model.predict(X_val)
y_pred = np.argmax(y_pred_multiclass, axis=1)
y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=8)

auc_score_adabelief = roc_auc_score(y_val_one_hot, y_pred_multiclass, average='macro', multi_class='ovr')
f1_adabelief = f1_score(y_val, y_pred, average='macro')

print(f"AUC (macro promedio usando AdaBelief): {auc_score_adabelief:.4f}")
print(f"F1 Score (macro promedio usando AdaBelief): {f1_adabelief:.4f}")

"""Uso del optimizador LAMB"""

###################################
#
#   Pruebas con optimizador LAMB
#
###################################

lamb_optimizer = tfa.optimizers.LAMB(learning_rate=0.001)

model = create_model_n_layers_n_filters(3, 32, size=16)
model.compile(optimizer=lamb_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), batch_size=batch_size, verbose=0)

y_pred_multiclass = model.predict(X_val)
y_pred = np.argmax(y_pred_multiclass, axis=1)
y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=8)

auc_score_lamb = roc_auc_score(y_val_one_hot, y_pred_multiclass, average='macro', multi_class='ovr')
f1_lamb = f1_score(y_val, y_pred, average='macro')

print(f"AUC (macro promedio usando LAMB): {auc_score_lamb:.4f}")
print(f"F1 Score (macro promedio usando LAMB): {f1_lamb:.4f}")

"""Gráfica comparativa de los distintos optimizadores"""

#######################################################
#
#   Gráfica comparativa de los optimizadores externos
#
#######################################################

optimizers = ['LAMB', 'AdaBelief', 'Ranger']
auc_scores = [auc_score_lamb, auc_score_adabelief, auc_score_ranger]
f1_scores = [f1_lamb, f1_adabelief, f1_ranger]

x = np.arange(len(optimizers))
width = 0.35

fig, ax = plt.subplots(figsize=(10, 6))

bars_auc = ax.bar(x - width/2, auc_scores, width, label='AUC (Macro Promedio)', color='royalblue')
bars_f1 = ax.bar(x + width/2, f1_scores, width, label='F1 Score (Macro Promedio)', color='seagreen')

ax.set_xlabel('Optimizadores')
ax.set_ylabel('Puntuación')
ax.set_title('Comparación de Optimizadores: AUC y F1 Score (Macro Promedio)')
ax.set_xticks(x)
ax.set_xticklabels(optimizers)
ax.legend(loc='lower left', bbox_to_anchor=(1, 1))

"""Test de Wilcoxon"""

########################################################
#
#   Validación cruzada sobre los distintos optimizadores
#
########################################################

from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=24)
auc_scores = {'LAMB': [], 'AdaBelief': [], 'Ranger': []}
f1_scores = {'LAMB': [], 'AdaBelief': [], 'Ranger': []}
optimizers = {'LAMB': lamb_optimizer, 'AdaBelief': adabelief_optimizer, 'Ranger': ranger_optimizer}

for name, optimizer in optimizers.items():
    print(f"Entrenando con el optimizador: {name}")

    for train_index, val_index in skf.split(X, y):
        X_train, X_val = X[train_index], X[val_index]
        y_train, y_val = y[train_index], y[val_index]

        model = None
        model = create_model_n_layers_n_filters(3, 32, size=16)
        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

        history = model.fit(X_train, y_train, epochs=15, batch_size=batch_size, verbose=0)

        y_pred_multiclass = model.predict(X_val)
        y_pred = np.argmax(y_pred_multiclass, axis=1)
        y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=8)

        auc_score = roc_auc_score(y_val_one_hot, y_pred_multiclass, average='macro', multi_class='ovr')
        f1 = f1_score(y_val, y_pred, average='macro')

        auc_scores[name].append(auc_score)
        f1_scores[name].append(f1)
    print(f"Optimización con {name} completada. AUC medio: {np.mean(auc_scores[name]):.4f}, F1 Score medio: {np.mean(f1_scores[name]):.4f}")

########################################################
#
#   Test de Wilcoxon de los distintos optimizadores
#
########################################################

from scipy.stats import wilcoxon

wilcoxon_results = []
optimizer_pairs = [('LAMB', 'AdaBelief'), ('LAMB', 'Ranger'), ('AdaBelief', 'Ranger')]

for opt1, opt2 in optimizer_pairs:
    stat, p_value = wilcoxon(auc_scores[opt1], auc_scores[opt2])
    wilcoxon_results.append((opt1, opt2, stat, p_value))

"""Gráfica comparativa del test estadístico de Wilcoxon"""

#########################################################
#
#   Gráfica comparativa del test estadístico de Wilcoxon
#
#########################################################

optimizer_pairs = [('LAMB', 'AdaBelief'), ('LAMB', 'Ranger'), ('AdaBelief', 'Ranger')]
p_values = []

print("\nResultados del Test de Wilcoxon (Valores p):")
for opt1, opt2 in optimizer_pairs:
    _, p_value = wilcoxon(auc_scores[opt1], auc_scores[opt2])
    p_values.append(p_value)
    print(f"{opt1} vs {opt2}: Valor p = {p_value:.4f}")

labels = [f"{opt1} vs {opt2}" for opt1, opt2 in optimizer_pairs]
x = np.arange(len(labels))

fig, ax = plt.subplots(figsize=(10, 6))

bars_p_values = ax.bar(x, p_values, color='lightgreen')

ax.set_xlabel('Comparación de Optimizadores')
ax.set_ylabel('Valor p')
ax.set_title('Resultados del Test de Wilcoxon (Valores p) para Comparación de Optimizadores')
ax.set_xticks(x)
ax.set_xticklabels(labels)

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## **Avanzado**

Mejora con el uso de redes pre-entrenadas con fine-tunning
"""

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.models import Model
from sklearn.metrics import roc_auc_score
import numpy as np

#########################################################
#
#   Uso de ResNet como red pre-entrenada
#
#########################################################

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3)) # modelo base con input de 32x32

for layer in base_model.layers:   # hacer que no se entrenen las capas
    layer.trainable = False

x = base_model.output
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
output = Dense(8, activation='softmax')(x)    # 8 clases de categorías

model = Model(inputs=base_model.input, outputs=output)

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

X_train_resized = tf.image.resize(X_train, (32, 32))
X_val_resized = tf.image.resize(X_val, (32, 32))

history = model.fit(X_train_resized, y_train, epochs=50, validation_data=(X_val_resized, y_val), batch_size=batch_size, verbose=1)


y_pred_pre = model.predict(X_val_resized)
y_val_one_hot = tf.keras.utils.to_categorical(y_val, num_classes=8)
auc_score = roc_auc_score(y_val_one_hot, y_pred_pre, average='macro', multi_class='ovr')

print(f"AUC (Area Under the Curve) para el conjunto de validación: {auc_score:.4f}")

"""# Capítulo II

# Librerías necesarias
"""

import numpy as np
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import RegexpTokenizer
from nltk.stem.snowball import SnowballStemmer

"""## **Básico**

Cargar el dataset que vamos a utilizar
"""

#################################
#
#   Cargar el dataset
#
#################################

url = 'https://www.dlsi.ua.es/~juanra/UA/dataset/dcadep/dcadep_melt_grades.csv.gz'
data = pd.read_csv(url, sep='\t', decimal=',')

data.fillna('', inplace=True)
print(data.head())

batch_size = 32
epochs = 20

"""Ejemplo para ver cuáles son las stopwords"""

nltk.download('stopwords')  # descargar stopwords
stopwords_es = set(stopwords.words('spanish'))
print(stopwords_es)

"""Ejemplo de uso del proceso de preprocesar frases"""

###############################################
#
#   Ejemplo utilizado para entender el proceso
#
###############################################

nltk.download('stopwords')
tokenizer = RegexpTokenizer(r'\w+')  # tokeniza palabras alfanumericas
stemmer = SnowballStemmer("spanish", ignore_stopwords=True)  # stemming en español
stop_words = set(stopwords.words('spanish'))  # stopwords en español

frases = [
    "Estoy estudiando cómo funcionan las redes de procesamiento de lenguaje natural.",
    "Desafíos de programación es la mejor asignatura, ¿verdad?"
]

frases_preprocesadas = []

for frase in frases:
    tokens = tokenizer.tokenize(frase.lower())
    stemmed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]
    frases_preprocesadas.append(' '.join(stemmed_tokens))

for original, procesada in zip(frases, frases_preprocesadas):
    print(f"Original: {original}")
    print(f"Procesada: {procesada}")
    print("-" * 50)

"""Preprocesado básico de palabras (minúsculas, lemmas, caracteres especiales y
stopwords)
"""

##################################
#
#   Preprocesado de feedback
#
##################################

nltk.download('stopwords')
tokenizer = RegexpTokenizer(r'\w+')  # tokeniza palabras alfanumericas
stemmer = SnowballStemmer("spanish", ignore_stopwords=True)  # stemming en español
stop_words = set(stopwords.words('spanish'))  # stopwords en español

feedback_preprocesado = []  # copia donde almacenaremos el nuevo feedback preprocesado

for feedback in data['feedback']:
    if feedback:
        tokens = tokenizer.tokenize(feedback.lower())   # tokenizamos el feedback de esa entrada
        stemmed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]  # stemming en español del feedback eliminando stopwords
        feedback_preprocesado.append(' '.join(stemmed_tokens))  # lo añadimos
    else:
        feedback_preprocesado.append('')  # si es vacio se mantiene vacio

data['feedback prep'] = feedback_preprocesado
print(data[['feedback', 'feedback prep']].head(10))  # mostrar feedback original y preprocesado	de las 10 primeras entradas

"""Filtrar por los que no están vacíos para mostrar más ejemplos"""

#################################################
#
#  Mostrar el preprocesado de feedback no vacíos
#
#################################################

feedback_no_vacio = data[data['feedback prep'] != '']
for _, row in feedback_no_vacio[['feedback', 'feedback prep']].head(4).iterrows():  # solo los 4 primeros feedback no vacíos
    print(f"feedback: {row['feedback']} | feedback prep: {row['feedback prep']}")

"""Librerías necesarias"""

from sklearn.model_selection import KFold            # validacion cruzada
from sklearn.feature_extraction.text import CountVectorizer   # BoW
from sklearn.metrics import mean_absolute_error

from tensorflow.keras.models import Sequential      # creacion del modelo regresor
from tensorflow.keras.layers import Dense, Dropout

import matplotlib.pyplot as plt     # gráficas

"""Creación del modelo (regresor)"""

#############################################
#
#     Creación del modelo regresor
#
#############################################

def create_regressor_model(X, y): # X sin transformar
    model = Sequential([
        Dense(128, activation='relu', input_shape=(X_vectorizado.shape[1],)),    # capa de entrada
        Dropout(0.2),
        Dense(64, activation='relu'),
        Dense(1, activation='linear')     # capa de salida para prediccion continua
    ])

    return model

"""Ejemplo de matrices dispersa y densa"""

#############################################
#
#     Ejemplo de matriz dispersa y densa
#
#############################################
vectorizador = CountVectorizer()
X_dispersa = vectorizador.fit_transform(["El gato corre", "El perro corre"])

X_densa = X_dispersa.toarray()

print("Matriz dispersa:\n", X_dispersa)
print("Matriz densa:\n", X_densa)

"""Aplicación de la validación cruzada (10-CV)"""

#############################################
#
#     Aplicación de la validación cruzada
#
#############################################

X = data['feedback prep']     # texto procesado
y = data['value']             # variable objetivo

vectorizador = CountVectorizer(max_features=500)  # BoW con las 500 palabras más importantes
X_vectorizado = vectorizador.fit_transform(X)

kf = KFold(n_splits=10)   # configuracion de la validacion cruzada
mae_scores = []

for train_index, test_index in kf.split(X_vectorizado):
    X_train, X_test = X_vectorizado[train_index], X_vectorizado[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    X_train = X_train.toarray()     # lo transformamos a formato denso
    X_test = X_test.toarray()

    model = create_regressor_model(X_train, y_train)
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_scores.append(mae)
    print(f"MAE: {mae}")

print(f"MAE promedio: {np.mean(mae_scores)}")

"""Gráfica comparativa para cada Fold"""

#############################################
#
#     Gráfica comparativa de MAE por Fold
#
#############################################

folds = range(1, len(mae_scores) + 1)  # cantidad de folds
plt.figure(figsize=(10, 6))
plt.plot(folds, mae_scores, marker='o', linestyle='-', color='b', label='MAE por fold')
plt.axhline(np.mean(mae_scores), color='r', linestyle='--', label=f'MAE promedio ({np.mean(mae_scores):.2f})')

plt.title('MAE en cada fold de la validación cruzada', fontsize=14)
plt.xlabel('Fold', fontsize=12)
plt.ylabel('MAE', fontsize=12)
plt.xticks(folds)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)

plt.show()

"""Aplicación de un par de redes neuronales

Modelo BoW
"""

#########################
#
#  Modelo de red BoW
#
#########################

def create_bow_model(X):
    model = Sequential([
        Dense(128, activation='relu', input_shape=(X,)),
        Dropout(0.2),
        Dense(64, activation='relu'),
        Dense(1, activation='linear')  # salida de predicciones continua
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

###############################################################
#
#     Aplicación de la validación cruzada con modelo BoW
#
###############################################################

X = data['feedback prep']     # texto procesado
y = data['value']             # variable objetivo

vectorizador = CountVectorizer(max_features=500)  # BoW con las 500 palabras más importantes
X_vectorizado = vectorizador.fit_transform(X)

kf = KFold(n_splits=10, shuffle=True, random_state=24)   # configuracion de la validacion cruzada
mae_bow_scores = []

for train_index, test_index in kf.split(X_vectorizado):
    X_train, X_test = X_vectorizado[train_index], X_vectorizado[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    X_train = X_train.toarray()     # lo transformamos a formato denso
    X_test = X_test.toarray()

    model = create_regressor_model(X_train, y_train)
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_bow_scores.append(mae)
    print(f"MAE: {mae}")

print(f"MAE promedio: {np.mean(mae_bow_scores)}")

"""Modelo LSTM (RNN)"""

from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

#########################
#
#  Modelo de red LSTM
#
#########################

def create_lstm_model(vocab_size, embedding_dim=50, input_length=10):
    model = Sequential([
        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),
        LSTM(64, return_sequences=False),  # LSTM con 64 unidades
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

###############################################################
#
#     Aplicación de la validación cruzada con modelo LSTM
#
###############################################################

kf = KFold(n_splits=10, shuffle=True, random_state=24)   # configuracion de la validacion cruzada
mae_lstm_scores = []

tokenizer = Tokenizer(num_words=500)    # tokenizer para convertir texto en secuencia numerica
tokenizer.fit_on_texts(data['feedback prep'])   # asociar valor a cada palabra de esa columna
sequences = tokenizer.texts_to_sequences(data['feedback prep']) # convertir a secuencia de indices
X_sequence = pad_sequences(sequences, maxlen=50)   # rellenar secuencias
y = np.array(data['value'])               # convertir a numpy array para usarlo en keras

for train_index, test_index in kf.split(X_sequence):                # el resto igual que en cualquier otro modelo
    X_train, X_test = X_sequence[train_index], X_sequence[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model = create_lstm_model(vocab_size=500, input_length=50, embedding_dim=50)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_lstm_scores.append(mae)
    print(f"MAE: {mae}")

print(f"MAE promedio: {np.mean(mae_lstm_scores)}")

"""Gráfica comparativa de los dos modelos"""

##############################################
#
#    Gráfica comparativa de los dos modelos
#
#############################################

plt.figure(figsize=(12, 6))
folds = range(1, len(mae_lstm_scores) + 1)

plt.plot(folds, mae_lstm_scores, marker='o', linestyle='-', color='b', label='LSTM MAE')
plt.plot(folds, mae_bow_scores, marker='x', linestyle='-', color='g', label='BoW MAE')

plt.axhline(np.mean(mae_lstm_scores), color='b', linestyle='--', label=f'LSTM MAE Promedio ({np.mean(mae_lstm_scores):.2f})')
plt.axhline(np.mean(mae_bow_scores), color='g', linestyle='--', label=f'BoW MAE Promedio ({np.mean(mae_bow_scores):.2f})')

plt.title('Comparación de MAE entre modelos LSTM y BoW por Fold', fontsize=14)
plt.xlabel('Fold', fontsize=12)
plt.ylabel('MAE', fontsize=12)
plt.xticks(folds)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)

plt.show()

"""Evaluación de la redes por actividad 1"""

##########################################
#
#   Evaluación de la actividad 1 (BoW)
#
##########################################

actividad_1 = data[data['activity'] == 1]   # solo contiene los datos de la actividad 1

vectorizador_1 = CountVectorizer(max_features=500)        # BoW con las 500 palabras más importantes
X_bow_1 = vectorizador_1.fit_transform(actividad_1['feedback prep'])
y_bow_1 = np.array(actividad_1['value'])    # convertirlo a numpy array

kf = KFold(n_splits=10, shuffle=True, random_state=24)    # configuracion de la validacion cruzada
mae_bow_1 = []

for train_index, test_index in kf.split(X_bow_1):
    X_train, X_test = X_bow_1[train_index].toarray(), X_bow_1[test_index].toarray()
    y_train, y_test = y_bow_1[train_index], y_bow_1[test_index]

    model = create_bow_model(X_train.shape[1])
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_bow_1.append(mae)

print(f"MAE promedio para actividad 1 (BoW): {np.mean(mae_bow_1)}")

##########################################
#
#   Evaluación de la actividad 1 (LSTM)
#
##########################################

actividad_1 = data[data['activity'] == 1]   # solo contiene los datos de la actividad 1

tokenizer_1 = Tokenizer(num_words=500)
tokenizer_1.fit_on_texts(actividad_1['feedback prep'])    # tokenizamos feedback prep de act1
sequences_1 = tokenizer_1.texts_to_sequences(actividad_1['feedback prep'])    # lo convertimos en secuencias
X_seq_1 = pad_sequences(sequences_1, maxlen=50)     # ponemos todas las secuencias a una long max de 50
y_1 = np.array(actividad_1['value'])    # lo convertimos a numpy array

kf = KFold(n_splits=10, shuffle=True, random_state=24)    # configuracion de la validacion cruzada
mae_lstm_1 = []

for train_index, test_index in kf.split(X_seq_1):
    X_train, X_test = X_seq_1[train_index], X_seq_1[test_index]
    y_train, y_test = y_1[train_index], y_1[test_index]

    model = create_lstm_model(vocab_size=500, input_length=50, embedding_dim=50)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_lstm_1.append(mae)

print(f"MAE promedio para actividad 1 (LSTM): {np.mean(mae_lstm_1)}")

"""Gráfica comparativa para cada uno de los modelos"""

##############################################################
#
#   Gráfica comparativa para la actividad 1 de ambos modelos
#
##############################################################

plt.figure(figsize=(12, 6))

folds = range(1, len(mae_bow_1) + 1)
plt.plot(folds, mae_bow_1, marker='o', linestyle='-', color='g', label='BoW MAE')
plt.plot(folds, mae_lstm_1, marker='x', linestyle='-', color='b', label='LSTM MAE')
plt.axhline(np.mean(mae_bow_1), color='g', linestyle='--', label=f'BoW MAE Promedio ({np.mean(mae_bow_1):.2f})')
plt.axhline(np.mean(mae_lstm_1), color='b', linestyle='--', label=f'LSTM MAE Promedio ({np.mean(mae_lstm_1):.2f})')

plt.title('Comparación de MAE por Fold (Actividad 1)', fontsize=14)
plt.xlabel('Fold', fontsize=12)
plt.ylabel('MAE', fontsize=12)
plt.xticks(folds)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)

plt.show()

"""Test de Wilcoxon"""

from scipy.stats import wilcoxon

"""Aplicación del Test de Wilcoxon"""

#####################################
#
#   Aplicación del Test de Wilcoxon
#
#####################################

stat, p_value = wilcoxon(mae_bow_1, mae_lstm_1)

if p_value < 0.05:
    print(f"Diferencia significativa (p = {p_value:.4f})")
else:
    print(f"No hay diferencia significativa (p = {p_value:.4f})")

"""Aplicación del Test de Wilcoxon (ambas actividades)"""

#############################################################
#
#   Aplicación del Test de Wilcoxon para ambas actividades
#
#############################################################

stat, p_value = wilcoxon(mae_bow_scores, mae_lstm_scores)

if p_value < 0.05:
    print(f"Diferencia significativa (p = {p_value:.4f})")
else:
    print(f"No hay diferencia significativa (p = {p_value:.4f})")

"""## **Medio**

Aplicar más arquitecturas de redes distintas a la del apartado básico
"""

#############################################################
#
#   Modelo de red CNN para capturar patrones en el texto
#
#############################################################

from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten

def create_cnn_model(vocab_size=5000, embedding_dim=50, input_length=100):
    model = Sequential([
        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),
        Conv1D(filters=128, kernel_size=5, activation='relu'),  # kernel_size tamaño del filtro para capturar patrones
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='linear')  # linear para salida continua (regresion)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

"""Aplicación de la validación cruzada a red CNN"""

#####################################
#
#   Aplicación de 10-CV a red CNN
#
#####################################

tokenizer = Tokenizer(num_words=5000)  # 500 palabras mas frecuentes
tokenizer.fit_on_texts(data['feedback prep'])

sequences = tokenizer.texts_to_sequences(data['feedback prep'])

X = pad_sequences(sequences, maxlen=100)
y = np.array(data['value'])

kf = KFold(n_splits=10, shuffle=True, random_state=24)
mae_scores_cnn = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model = create_cnn_model(vocab_size=5000, embedding_dim=50, input_length=100)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_scores_cnn.append(mae)

print(f"MAE promedio: {np.mean(mae_scores_cnn)}")

"""Aplicación de la validación cruzada a red GRU"""

#########################
#
#   Modelo de red GRU
#
#########################

from tensorflow.keras.layers import GRU

def create_gru_model(vocab_size, embedding_dim=50, input_length=100):
    model = Sequential([
        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),
        GRU(64, return_sequences=False),
        Dropout(0.2),
        Dense(64, activation='relu'),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

#####################################
#
#   Aplicación de 10-CV a red GRU
#
#####################################

tokenizer = Tokenizer(num_words=5000)    # igual que en la CNN
tokenizer.fit_on_texts(data['feedback prep'])

sequences = tokenizer.texts_to_sequences(data['feedback prep'])

X = pad_sequences(sequences, maxlen=100)
y = np.array(data['value'])

kf = KFold(n_splits=10, shuffle=True, random_state=24)
mae_scores_gru = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model = create_gru_model(vocab_size=5000, embedding_dim=50, input_length=100)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test).flatten()  # aplanar para que coincida con y_test
    mae = mean_absolute_error(y_test, y_pred)
    mae_scores_gru.append(mae)
    print(f"MAE del fold: {mae}")

print(f"MAE promedio: {np.mean(mae_scores_gru)}")

"""Gráfica comparativa de los modelos CNN y GRU

"""

######################################
#
#   Gráfica comparativa de CNN y GRU
#
######################################

folds = range(1, len(mae_scores_cnn) + 1)

plt.figure(figsize=(10, 6))
plt.plot(folds, mae_scores_cnn, marker='o', label='CNN MAE', linestyle='-', color='blue')
plt.plot(folds, mae_scores_gru, marker='x', label='GRU MAE', linestyle='--', color='green')

plt.axhline(y=sum(mae_scores_cnn) / len(mae_scores_cnn), color='blue', linestyle='dotted', label=f'CNN Promedio ({sum(mae_scores_cnn) / len(mae_scores_cnn):.2f})')
plt.axhline(y=sum(mae_scores_gru) / len(mae_scores_gru), color='green', linestyle='dotted', label=f'GRU Promedio ({sum(mae_scores_gru) / len(mae_scores_gru):.2f})')

plt.title('Comparación de MAE por Fold (CNN vs GRU)')
plt.xlabel('Fold')
plt.ylabel('MAE')
plt.xticks(folds)
plt.legend()
plt.grid(True)
plt.tight_layout()

plt.show()

"""Ajustes combinados (número de capas, tipo de capas, normalización)

Nuevo modelo CNN modificado
"""

#########################################
#
#   Nuevo modelo de red CNN modificada
#
#########################################

from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, BatchNormalization

def create_new_cnn_model(vocab_size=5000, embedding_dim=50, input_length=100):
    model = Sequential([
        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),
        Conv1D(filters=128, kernel_size=5, activation='relu'),  # kernel_size tamaño del filtro para capturar patrones
        BatchNormalization(),       # normalizacion para estabilizar el entrenamiento
        MaxPooling1D(pool_size=2),
        Conv1D(filters=64, kernel_size=3, activation='relu'),  # segunda capa convolucional
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='linear')  # linear para salida continua (regresion)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

#############################################
#
#   Aplicación de 10-CV a red CNN modifcada
#
#############################################

tokenizer = Tokenizer(num_words=5000)  # 5000 palabras mas frecuentes
tokenizer.fit_on_texts(data['feedback prep'])

sequences = tokenizer.texts_to_sequences(data['feedback prep'])   # secuencia numerica basada en mas frecuente

X = pad_sequences(sequences, maxlen=100)    # maxlen de secuencia 100
y = np.array(data['value'])

kf = KFold(n_splits=10, shuffle=True, random_state=24)      # config del 10CV
mae_scores_new_cnn = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model = create_new_cnn_model(vocab_size=5000, embedding_dim=50, input_length=100)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_scores_new_cnn.append(mae)

print(f"MAE promedio: {np.mean(mae_scores_new_cnn)}")

"""Nuevo modelo de red GRU modificada"""

#########################
#
#   Modelo de red GRU
#
#########################

from tensorflow.keras.layers import GRU, Bidirectional

def create_new_gru_model(vocab_size, embedding_dim=50, input_length=100):
    model = Sequential([
        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),
        Bidirectional(GRU(64, return_sequences=True)),  # capa bidireccional
        BatchNormalization(),  # normalizacion despues de GRU
        Dropout(0.2),
        GRU(32),    # segunda capa GRU
        Dense(64, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

#############################################
#
#   Aplicación de 10-CV a red GRU modifcada
#
#############################################

tokenizer = Tokenizer(num_words=5000)  # 5000 palabras mas frecuentes
tokenizer.fit_on_texts(data['feedback prep'])

sequences = tokenizer.texts_to_sequences(data['feedback prep'])   # secuencia numerica basada en mas frecuente

X = pad_sequences(sequences, maxlen=100)    # maxlen de secuencia 100
y = np.array(data['value'])

kf = KFold(n_splits=10, shuffle=True, random_state=24)      # config del 10CV
mae_scores_new_gru = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model = create_new_gru_model(vocab_size=5000, embedding_dim=50, input_length=100)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_scores_new_gru.append(mae)

print(f"MAE promedio: {np.mean(mae_scores_new_gru)}")

"""Gráfica comparativa para cada modelo modificado"""

##################################################
#
#   Gráfica comparativa de CNN y GRU modificados
#
##################################################

folds = range(1, len(mae_scores_new_cnn) + 1)

plt.figure(figsize=(10, 6))
plt.plot(folds, mae_scores_new_cnn, marker='o', label='NEW CNN MAE', linestyle='-', color='blue')
plt.plot(folds, mae_scores_new_gru, marker='x', label='NEW GRU MAE', linestyle='--', color='green')

plt.axhline(y=sum(mae_scores_new_cnn) / len(mae_scores_new_cnn), color='blue', linestyle='dotted', label=f'CNN Promedio ({sum(mae_scores_new_cnn) / len(mae_scores_new_cnn):.2f})')
plt.axhline(y=sum(mae_scores_new_gru) / len(mae_scores_new_gru), color='green', linestyle='dotted', label=f'GRU Promedio ({sum(mae_scores_new_gru) / len(mae_scores_new_gru):.2f})')

plt.title('Comparación de MAE por Fold (CNN vs GRU) Modificados')
plt.xlabel('Fold')
plt.ylabel('MAE')
plt.xticks(folds)
plt.legend()
plt.grid(True)
plt.tight_layout()

plt.show()

"""Uso de redes pre-entrenadas aplicadas a nuestro problema"""

!pip install transformers     # instalar transformers

"""Uso de red pre-entrenada con Word Embeddings (GloVe)"""

!wget http://nlp.stanford.edu/data/glove.6B.zip
!unzip glove.6B.zip     # descargar GloVe

#########################
#
#   Cargar la red GloVe
#
#########################

def load_glove_embeddings(filepath, vocab_size, embedding_dim, tokenizer):
    embeddings_index = {}
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            values = line.split()
            word = values[0]
            coefs = np.asarray(values[1:], dtype='float32')
            embeddings_index[word] = coefs

    embedding_matrix = np.zeros((vocab_size, embedding_dim))    # matriz de embeddings
    for word, i in tokenizer.word_index.items():
        if i < vocab_size:
            embedding_vector = embeddings_index.get(word)
            if embedding_vector is not None:
                embedding_matrix[i] = embedding_vector

    return embedding_matrix

#########################
#
#   Crear modelo GloVe
#
#########################

def create_glove_model(embedding_matrix, input_length):
    model = Sequential([
        Embedding(input_dim=embedding_matrix.shape[0],
                  output_dim=embedding_matrix.shape[1],
                  weights=[embedding_matrix],
                  input_length=input_length,
                  trainable=False),       # congelado para que no se entrene
        Conv1D(filters=128, kernel_size=5, activation='relu'),
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='linear')  # salida continua (regresion)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
    return model

###################################
#
#   Aplicar 10-CV al modelo GloVe
#
###################################

tokenizer = Tokenizer(num_words=5000)           # preparativo de datos igual que en todos
tokenizer.fit_on_texts(data['feedback prep'])
sequences = tokenizer.texts_to_sequences(data['feedback prep'])
X = pad_sequences(sequences, maxlen=100)
y = np.array(data['value'])

embedding_matrix = load_glove_embeddings('glove.6B.50d.txt', vocab_size=5000, embedding_dim=50, tokenizer=tokenizer)    # cargar la matriz

kf = KFold(n_splits=10, shuffle=True, random_state=24)      # config del 10CV
mae_scores_glove = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model = create_glove_model(embedding_matrix, input_length=100)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)

    y_pred = model.predict(X_test).flatten()
    mae = mean_absolute_error(y_test, y_pred)
    mae_scores_glove.append(mae)

print(f"MAE promedio GloVe: {np.mean(mae_scores_glove)}")

"""Gráfica representativa para el modelo de red pre-entrenada GloVe"""

#########################################
#
#   Gráfica representativa de red GloVe
#
#########################################

folds = range(1, len(mae_scores_glove) + 1)

plt.figure(figsize=(10, 6))
plt.plot(folds, mae_scores_glove, marker='o', label='GloVe MAE', linestyle='-', color='blue')

plt.axhline(y=sum(mae_scores_glove) / len(mae_scores_glove), color='blue', linestyle='dotted', label=f'GloVe Promedio ({sum(mae_scores_glove) / len(mae_scores_glove):.2f})')

plt.title('Representación del valor de MAE por fold con GloVe')
plt.xlabel('Fold')
plt.ylabel('MAE')
plt.xticks(folds)
plt.legend()
plt.grid(True)
plt.tight_layout()

plt.show()

"""Test de Wilcoxon sobre los modelos BoW, LSTM, CNN y GRU"""

from scipy.stats import wilcoxon

##################################################
#
#   Test de Wilcoxon sobre los distintos modelos
#
##################################################

p_bow_lstm = wilcoxon(mae_bow_scores, mae_lstm_scores).pvalue
p_bow_cnn = wilcoxon(mae_bow_scores, mae_scores_cnn).pvalue
p_bow_gru = wilcoxon(mae_bow_scores, mae_scores_gru).pvalue
p_lstm_cnn = wilcoxon(mae_lstm_scores, mae_scores_cnn).pvalue
p_lstm_gru = wilcoxon(mae_lstm_scores, mae_scores_gru).pvalue
p_cnn_gru = wilcoxon(mae_scores_cnn, mae_scores_gru).pvalue

comparisons = ['BoW vs LSTM', 'BoW vs CNN', 'BoW vs GRU',
               'LSTM vs CNN', 'LSTM vs GRU', 'CNN vs GRU']
p_values = [p_bow_lstm, p_bow_cnn, p_bow_gru, p_lstm_cnn, p_lstm_gru, p_cnn_gru]

plt.figure(figsize=(10, 6))
plt.bar(comparisons, p_values, color='skyblue', edgecolor='black')
plt.axhline(0.05, color='red', linestyle='--', label='Nivel de significancia (p=0.05)')
plt.title('Test de Wilcoxon entre modelos', fontsize=14)
plt.ylabel('p-value', fontsize=12)
plt.xticks(rotation=45, fontsize=10)
plt.legend()
plt.tight_layout()

plt.show()